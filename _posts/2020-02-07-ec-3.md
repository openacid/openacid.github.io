---
title:      "Erasure-Code-擦除码-3-实现篇"
authors:
    - xp
categories:
    - storage
tags:
    - storage
    - ec
    - erasure-code
    - distributed
    - replication
    - 擦除码
    - 纠删码
    - 伽罗瓦
    - 域
    - 伽罗瓦域
    - GF256

refs:
    - "Vandermonde":      https://en.wikipedia.org/wiki/Vandermonde_matrix                     "Vandermonde matrix"
    - "Cauchy":           https://en.wikipedia.org/wiki/Cauchy_matrix                          "Cauchy matrix"
    - "failure-rate":     https://www.backblaze.com/blog/hard-drive-reliability-stats-q1-2016/ "HDD Failure Rate"
    - "RAID":             https://zh.wikipedia.org/wiki/RAID                                   "RAID"
    - "RAID-5":           https://zh.wikipedia.org/wiki/RAID#RAID_5                            "RAID-5"
    - "RAID-6":           https://zh.wikipedia.org/wiki/RAID#RAID_6                            "RAID-6"
    - "Finite-Field":     https://en.wikipedia.org/wiki/Finite_field                           "Finite-Field"
    - "Galois-Field":     https://en.wikipedia.org/wiki/Finite_field                           "Galois-Field"
    - "Reed-Solomon":     https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction  "Reed-Solomon error correction"
    - "Erasure-Code":     https://en.wikipedia.org/wiki/Erasure_code                           "Erasure-Code"
    - "Prime-Polynomial": https://en.wikipedia.org/wiki/Irreducible_polynomial                 "Prime-Polynomial"
    - "Field-Extension":  https://en.wikipedia.org/wiki/Field_extension                        "Field-Extension"
    - "Complex-Number":   https://en.wikipedia.org/wiki/Irreducible_polynomial#Field_extension "Complex-Number"
    - "Hamming-7-4":      https://en.wikipedia.org/wiki/Hamming(7,4)                           "Hamming(7, 4)"
    - "Generator-Matrix": https://en.wikipedia.org/wiki/Generator_matrix                       "Generator-Matrix"
    - "第一篇:原理":      https://blog.openacid.com/storage/ec-1                               "第一篇:Erasure-Code-擦除码-1-原理篇"
    - "第二篇:实现":      https://blog.openacid.com/storage/ec-2                               "第二篇:Erasure-Code-擦除码-2-实现篇"
    - "第三篇:极限":      https://blog.openacid.com/storage/ec-3                               "第三篇:Erasure-Code-擦除码-3-极限篇"
    - "费马小定理的群论的证明":    https://en.wikipedia.org/wiki/Proofs_of_Fermat%27s_little_theorem#Proofs_using_group_theory "费马小定理的群论的证明"

article:
    image: /post-res/ec-2/ec-3-banner.png

pdf: false

mathjax: true
toc: true
toc_label: 本文目录
toc_sticky: true
---

# 书接上回

上一篇 [第一篇:实现][] 中, 我们介绍完了基于GF(2⁸)伽罗瓦域的标准实现以及做了正确性分析,

我们也提到:

> 在EC的计算中, 编解码是一个比较耗时的过程,
> 因此业界也在不断寻找优化的方法, 不论从理论算法上还是从计算机指令的优化上,
> 于是下一篇我们将介绍如何把EC实现为一个高效的实现.

本文我们来介绍, 在实际生产环境使用时还需做哪些优化,
来将EC打造成一个稳定高效的实现.

- [第一篇:原理] 再上一篇 🤔
- [第二篇:实现] 上一篇 🤔
- [第三篇:极限] 我们在这 😁


# 算法优化

# 工程优化

# SIMD

# Buffering

# 数据更新
add=remove

# 参数配置

# 垃圾回收
simhash

# 分析

# 波松/正太

-   需要对存储策略规划的架构师, 可以直接参考数值分析部分 [分析]({{page.url}}#ec-analysis).

## 数据恢复IO优化: LRC: [Local-Reconstruction-Code]

当 EC 进行数据恢复的时候, 需要k个块参与数据恢复, 直观上,
每个数据块损坏都需要k倍的IO消耗.

为了缓解这个问题, 一种略微提高冗余度, 但可以大大降低恢复IO的算法被提出:
[Local-Reconstruction-Code], 简称 LRC.

LRC的思路很简单, 在原来的 EC 的基础上,
对所有的数据块分组对每组在做1次 $ k' + 1 $ 的 EC.
k' 是二次分组的每组的数据块的数量.



### LRC 的校验块生成

$$
\begin{aligned}
\overbrace{d_1 + d_2 + d_3}^{y_{1,1}} + \overbrace{d_4 + d_5 + d_6}^{y_{1,2}} & = y_1 \\
d_1 + 2d_2 + 2^2d_3 + 2^3d_4 + 2^4d_5 + 2^5d_6                                & = y_2 \\
d_1 + 3d_2 + 3^2d_3 + 3^3d_4 + 3^4d_5 + 3^5d_6                                & = y_3
\end{aligned}
$$

最终保存的块是所有的数据块: $ d_1, d_2, d_3, d_4, d_5, d_6 $,
和校验块 $ y_{1,1}, y_{1,2}, y_2, y_3 $.

这里不需要保存 $ y_1 $ 因为 $ y_1 = y_{1,1} + y_{1,2} $

对于 LRC的EC来说, 它的生成矩阵前k行不变,
去掉了标准EC的第k+1行, 多出2个局部的校验行:

$$
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
\hline \\
1 & 1 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 1 & 1 \\
\hline \\
1 & 2 & 2^2 & 2^3 & 2^4 & 2^5 \\
1 & 3 & 3^2 & 3^3 & 3^4 & 3^5 \\
\end{bmatrix}
\times
\begin{bmatrix}
d_1 \\
d_2 \\
d_3 \\
d_4 \\
d_5 \\
d_6
\end{bmatrix} =
\begin{bmatrix}
d_1 \\
d_2 \\
d_3 \\
d_4 \\
d_5 \\
d_6 \\
y_{1,1} \\
y_{1,2} \\
y_2 \\
y_3 \\
\end{bmatrix}
$$



### LRC 的数据恢复

LRC 的数据恢复和标准的EC类似, 除了2点不同:

-   在选择校验块的行生成解码矩阵的时候,
    如果某第k+i行没有覆盖到任何损坏的数据的话,
    是无法提供有效性信息, 需要跳过的.

    例如 $ d_4 $ 损坏时, 不能像标准EC那样选择第7行 `1 1 1 0 0 0`
    这行作为补充的校验行生成解码矩阵, 必须略过第7行, 使用第8行.

-   不是所有的情况下, m个数据损坏都可以通过加入m个校验行来恢复.
    因为LRC的生成矩阵没有遵循 [Vandermonde] 矩阵的规则,
    不能保证任意k行都是满秩的.

#  工程优化

插播一条广告:
徐同学的博客中给出了很好的EC工程实现的介绍,
推荐!: [实现高性能纠删码引擎](http://www.templex.xyz/blog/101/writers.html)




##  可靠性分析

在可靠性方面, 假设 EC 的配置是k个数据块, m个校验块.
根据 EC 的定义,k+m个块中, 任意丢失m个都可以将其找回.
这个 EC 组的丢失数据的风险就是丢失m+1个块或更多的风险:

$$
\sum_{i=m+1}^{k+m} {k+m \choose i} p^{i} (1-p)^{k+m-i}
$$

这里p是单块数据丢失的风险,一般选择磁盘的日损坏率: 大约是`0.0001`.
p一般很小所以近似就只看第1项:

$$
{k+m \choose m+1} p^{m+1} (1-p)^{k-1}
$$

2个校验块和3副本的可靠性对比(取m=2):

| k   | m   | 丢数据风险                                                      |
| :-- | :-- | :--                                                             |
| 1   | 2   | $ 1 \times 10^{-12} $ (1个数据块+2个校验块 可靠性 和 3副本等价) |
| 2   | 2   | $ 3 \times 10^{-12} $                                           |
| 3   | 2   | $ 9 \times 10^{-12} $                                           |
| 10  | 2   | $ 2 \times 10^{-10} $ (10+2 和 12盘服务器的 [RAID-6] 等价)      |
| 32  | 2   | $ 5 \times 10^{-9} $                                            |
| 64  | 2   | $ 4 \times 10^{-8} $                                            |

3个校验块和4副本的可靠性对比(取m=3):

| k   | m   | 丢数据风险                                                      |
| :-- | :-- | :--                                                             |
| 1   | 3   | $ 1 \times 10^{-16} $ (1个数据块+3个校验块 可靠性 和 4副本等价) |
| 2   | 3   | $ 5 \times 10^{-16} $                                           |
| 3   | 3   | $ 2 \times 10^{-15} $                                           |
| 10  | 3   | $ 7 \times 10^{-14} $                                           |
| 32  | 3   | $ 5 \times 10^{-12} $                                           |
| 64  | 3   | $ 7 \times 10^{-11} $                                           |

4个校验块和5副本的可靠性对比(取m=4):

| k   | m   | 丢数据风险                                                      |
| :-- | :-- | :--                                                             |
| 1   | 4   | $ 1 \times 10^{-20} $ (1个数据块+4个校验块 可靠性 和 5副本等价) |
| 2   | 4   | $ 6 \times 10^{-20} $                                           |
| 3   | 4   | $ 2 \times 10^{-19} $                                           |
| 10  | 4   | $ 2 \times 10^{-17} $                                           |
| 32  | 4   | $ 4 \times 10^{-15} $                                           |
| 64  | 4   | $ 1 \times 10^{-13} $                                           |



## IO消耗

以一个 EC 组来分析,
1个块损坏的概率是 $ p $, 这个组中有块损坏的概率是:
$ 1 - (1-p)^{k+m} \approx (k+m)p $

每次数据损坏都需要读取全组的数据进行恢复.
不论1块损坏还是多块损坏, 数据恢复都是读取1次, 输出1或多次.
恢复数据的输出比较小, 1般是1, 所以可以忽略.

每存储一个字节一天数据恢复产生的传输量是(blocksize是一个数据块或校验块的大小):

$$
\frac{(k+m)p \times (k+m) \times blocksize}
{(k+m) \times blocksize} = (k+m)p
$$

也就是说, 使用 EC 每存储`1TB`的数据,
每天(因为我们取的数据损坏概率是按天计算的)用于数据恢复而产生的IO是
`k * 0.1GB / TB`

磁盘的IO大致上也等同于网络流量, 因为大部分实现必须将数据分布到不同的服务器上.

> NOTE:<br/>
> 随着 `k`的增加, 整体成本虽然会下降(`1+m/k`),
> 但数据恢复的IO开销也会随着k(近似于)线性的增长.

例如:

假设`k+m = 12`:

如果整个集群有 `100PB` 数据,
每天用于恢复数据的网络传输是 `100TB`.

假设单台存储服务器的容量是`30TB`,
每台服务器每天用于数据恢复的数据输出量是 `30GB`,
如果数据恢复能平均到每天的每1秒, 最低的带宽消耗是:
`30GB / 86400 sec/day = 3.0Mbps`.

但一般来说数据恢复不会在时间上很均匀的分布,
这个带宽消耗需要预估10倍到100倍.




> EC擦除码系列:
> - [第一篇:原理]
> - [第二篇:实现]
> - [第三篇:极限]

{% include build_ref %}
